{"cells":[{"cell_type":"markdown","metadata":{"id":"NGGrt9EYlCqY"},"source":["\n","\n","# Hyperparameter Tuning Practice\n","\n","## *Data Science Unit 4 Sprint 2 Assignment 3*\n","\n","# Gridsearch Hyperparameters\n","\n","In the guided project, you learned how to use sklearn's `GridsearchCV` and `keras-tuner` libraries to tune the hyperparameters of a neural network model. For your module project you'll continue using these two libraries, however we are going to make things a little more interesting for you. \n","\n","Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. \n","\n","\n","\n","**Don't forget to switch to GPU on Colab!**"]},{"cell_type":"markdown","metadata":{"id":"C7oEgGCV3_hY"},"source":["## 0.1 Imports and installs"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5855,"status":"ok","timestamp":1639004211787,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":480},"id":"DxctNMPb7mNY","outputId":"7ae83304-2e15-4095-c3e2-dec49018a424"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: keras-tuner in c:\\users\\jeff\\anaconda3\\lib\\site-packages (1.1.3)\n","Requirement already satisfied: kt-legacy in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from keras-tuner) (1.0.4)\n","Requirement already satisfied: requests in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from keras-tuner) (2.25.1)\n","Requirement already satisfied: packaging in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from keras-tuner) (21.3)\n","Requirement already satisfied: tensorboard in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from keras-tuner) (2.9.1)\n","Requirement already satisfied: ipython in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from keras-tuner) (7.22.0)\n","Requirement already satisfied: numpy in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from keras-tuner) (1.20.1)\n","Requirement already satisfied: jedi>=0.16 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.17.2)\n","Requirement already satisfied: setuptools>=18.5 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (62.3.2)\n","Requirement already satisfied: decorator in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (5.0.6)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (3.0.17)\n","Requirement already satisfied: pickleshare in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.7.5)\n","Requirement already satisfied: colorama in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.4.4)\n","Requirement already satisfied: backcall in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (0.2.0)\n","Requirement already satisfied: pygments in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (2.8.1)\n","Requirement already satisfied: traitlets>=4.2 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from ipython->keras-tuner) (5.0.5)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from packaging->keras-tuner) (2.4.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.4)\n","Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2020.12.5)\n","Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (0.36.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (2.9.1)\n","Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (3.3.7)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.8.1)\n","Requirement already satisfied: absl-py>=0.4 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.1.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (3.19.4)\n","Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (1.43.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from tensorboard->keras-tuner) (0.6.1)\n","Requirement already satisfied: six>=1.9.0 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (5.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n","Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->keras-tuner) (0.7.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.4)\n","Requirement already satisfied: wcwidth in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n","Requirement already satisfied: ipython-genutils in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from traitlets>=4.2->ipython->keras-tuner) (0.2.0)\n","Requirement already satisfied: zipp>=0.5 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.4.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jeff\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-1-a04cd5b873a9>:25: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n","  from kerastuner.tuners import RandomSearch, BayesianOptimization, Sklearn\n"]}],"source":["# native python libraries imports \n","import math\n","from time import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# sklearn imports \n","import sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","\n","# keras imports \n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.activations import relu, sigmoid\n","from tensorflow.keras.optimizers import Adam, SGD\n","from tensorflow.keras.utils import get_file\n","\n","# required for compatibility between sklearn and keras\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","\n","# install keras-tuner\n","!pip install keras-tuner\n","from kerastuner.tuners import RandomSearch, BayesianOptimization, Sklearn\n","from kerastuner.engine.hyperparameters import HyperParameters"]},{"cell_type":"markdown","metadata":{"id":"YMBS8CRBzYqB"},"source":["## 0.2 Load quickdraw data"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Kr8w6IX37mNa"},"outputs":[],"source":["def load_quickdraw10(cached=False):\n","    \"\"\"\n","    Loads the normalized quickdraw10 imageset into shuffled train, test arrays\n","    \n","    Parameters\n","    ----------\n","    cached: bool (default False)\n","        set whether to load from remote url site or local root folder\n","    Returns\n","    ----------\n","    X_train, X_test, y_train, y_test: numpy arrays\n","    \"\"\"\n","    \n","    if not cached:\n","        URL_ = \"https://github.com/LambdaSchool/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/quickdraw10.npz?raw=true\"\n","        datapath = tf.keras.utils.get_file('./quickdraw10.npz', origin=URL_, extract=False)\n","    else:\n","        datapath = \"../quickdraw10.npz\"\n","\n","    data = np.load(datapath)\n","    \n","    # normalize your image data\n","    max_pixel_value = 255\n","    X = data['arr_0']/max_pixel_value\n","    Y = data['arr_1']\n","        \n","    return train_test_split(X, Y, shuffle=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2295,"status":"ok","timestamp":1631203627574,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"UjU5nY3e7mNc","outputId":"1c297e7d-8b3e-4284-cc83-c9ecbffe588f"},"outputs":[],"source":["X_train, X_test, y_train, y_test = load_quickdraw10(cached=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"qkvBPoUy7mNd"},"outputs":[{"data":{"text/plain":["(75000, 784)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["X_train.shape"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"e4dx6VA07mNe"},"outputs":[{"data":{"text/plain":["(75000,)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["y_train.shape"]},{"cell_type":"markdown","metadata":{"id":"bXsWtj8Z7mNf"},"source":["_____\n","\n","# Experiment 1\n","\n","## Tune Hyperperameters using Enhanced GridsearchCV \n","\n","We are going to use GridsearchCV again to tune a deep learning model however we are going to add some additional functionality to our gridsearch. \n","\n","Specifically, we are going to automate the generation of how many nodes to use in a layer and how many layers to use in a model! \n","\n","By the way, yes, there is a function within a function. Try to not let that bother you. An alternative to this would be to create a class. If you're up for the challenge give it a shot. However, consider this a stretch goal that you come back to after you finish going through this assignment. \n","\n","\n","### Objective \n","\n","The objective of this experiment is to show you how to automate the generation of layers and layer nodes for the purposes of gridsearch. <br>\n","Up until now, we've been manually selecting the number of layers and layer nodes."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"USXjs7Hk71Hy"},"outputs":[],"source":["# Function to create model, required for KerasClassifier\n","def create_model(n_layers,  first_layer_nodes, last_layer_nodes, act_funct =\"relu\", negative_node_incrementation=True):\n","    \"\"\"\"\n","    Returns a compiled keras model \n","    \n","    Parameters\n","    ----------\n","    n_layers: int \n","        number of hidden layers in model \n","        To be clear, this excludes the input and output layer.\n","        \n","    first_layer_nodes: int\n","        Number of nodes in the first hidden layer \n","\n","    last_layer_nodes: int\n","        Number of nodes in the last hidden layer (this is the layer just prior to the output layer)\n","        \n","     act_funct: string \n","         Name of activation function to use in hidden layers (this excludes the output layer)\n","        \n","    Returns\n","    -------\n","    model: keras object \n","    \"\"\"\n","    \n","    def gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation=True):\n","        \"\"\"\n","        Generates and returns the number of nodes in each hidden layer. \n","        To be clear, this excludes the input and output layer. \n","\n","        Note\n","        ----\n","        Number of nodes in each layer is linearly incremented. \n","        For example, gen_layer_nodes(5, 500, 100) will generate [500, 400, 300, 200, 100]\n","\n","        Parameters\n","        ----------\n","        n_layers: int\n","            Number of hidden layers\n","            This values should be 2 or greater \n","\n","        first_layer_nodes: int\n","\n","        last_layer_nodes: int\n","\n","        Returns\n","        -------\n","        layers: list of ints\n","            Contains number of nodes for each layer \n","        \"\"\"\n","\n","        # throws an error if n_layers is less than 2 \n","        assert n_layers >= 2, \"n_layers must be 2 or greater\"\n","\n","        layers = []\n","\n","        # PROTIP: IF YOU WANT THE NODE INCREMENTATION TO BE SPACED DIFFERENTLY\n","        # THEN YOU'LL NEED TO CHANGE THE WAY THAT IT'S CALCULATED - HAVE FUN!\n","        # when set to True number of nodes are decreased for subsequent layers \n","        # NOTE: the order of the number of nodes doesn't matter\n","        if negative_node_incrementation:\n","            # subtract this amount from previous layer's nodes in order to increment towards smaller numbers \n","            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n","            \n","        # when set to False number of nodes are increased for subsequent layers\n","        else:\n","            # add this amount from previous layer's nodes in order to increment towards larger numbers \n","            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n","\n","        nodes = first_layer_nodes\n","\n","        for i in range(1, n_layers+1):\n","\n","            layers.append(math.ceil(nodes))\n","\n","            # increment nodes for next layer \n","            nodes = nodes + nodes_increment\n","\n","        return layers\n","    \n","    # create model\n","    model = Sequential()\n","    \n","    n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n","    \n","    for i in range(1, n_layers):\n","        if i==1:\n","            model.add(Dense(first_layer_nodes, input_dim=X_train.shape[1], activation=act_funct))\n","        else:\n","            model.add(Dense(n_nodes[i-1], activation=act_funct))\n","            \n","            \n","    # output layer \n","    model.add(Dense(10, # 10 unit/neurons in output layer because we have 10 possible labels to predict  \n","                    activation='softmax')) # use softmax for a label set greater than 2            \n","    \n","    # Compile model\n","    model.compile(loss='sparse_categorical_crossentropy', \n","                  optimizer='adam', # adam is a good default optimizer \n","                  metrics=['accuracy'])\n","    \n","    # do not include model.fit() inside the create_model function\n","    # KerasClassifier is expecting a complied model \n","    return model\n"]},{"cell_type":"markdown","metadata":{"id":"YO-x0nqt7mNh"},"source":["## 1.1 Explore `create_model`\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-1hnjQHKW19w"},"source":["The helper function `gen_layer_nodes()` which is contained inside `create_model()` <br>\n","returns a list containing the number of nodes for each successive layer.<br>\n","\n","Let's check that `gen_layer_nodes()` behaves as expected. <br>\n","In other words, we'll perform a **Unit Test!**"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"YiPXu0p_Qco_"},"outputs":[],"source":["def gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation=True):\n","    \"\"\"\n","    Generates and returns the number of nodes in each hidden layer. \n","    To be clear, this excludes the input and output layer. \n","\n","    Note\n","    ----\n","    Number of nodes in each layer is linearly incremented. \n","    For example, gen_layer_nodes(5, 500, 100) will generate [500, 400, 300, 200, 100]\n","\n","    Parameters\n","    ----------\n","    n_layers: int\n","        Number of hidden layers\n","        This values should be 2 or greater \n","\n","    first_layer_nodes: int\n","\n","    last_layer_nodes: int\n","\n","    Returns\n","    -------\n","    layers: list of ints\n","        Contains number of nodes for each layer \n","    \"\"\"\n","\n","    # throws an error if n_layers is less than 2 \n","    assert n_layers >= 2, \"n_layers must be 2 or greater\"\n","\n","    layers = []\n","\n","    # PROTIP: IF YOU WANT THE NODE INCREMENTATION TO BE SPACED DIFFERENTLY\n","    # THEN YOU'LL NEED TO CHANGE THE WAY THAT IT'S CALCULATED - HAVE FUN!\n","    # when set to True number of nodes are decreased for subsequent layers \n","    # NOTE: the order of the number of nodes doesn't matter\n","    if negative_node_incrementation:\n","        # subtract this amount from previous layer's nodes in order to increment towards smaller numbers \n","        nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n","        #print(f'nodes increment = {nodes_increment}')\n","        \n","    # when set to False number of nodes are increased for subsequent layers\n","    else:\n","        # add this amount from previous layer's nodes in order to increment towards larger numbers \n","        nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n","        #print(f'nodes increment = {nodes_increment}')\n","\n","    nodes = first_layer_nodes\n","\n","    for i in range(1, n_layers+1):\n","\n","        layers.append(math.ceil(nodes))\n","\n","        # increment nodes for next layer \n","        nodes = nodes + nodes_increment\n","\n","    return layers"]},{"cell_type":"markdown","metadata":{"id":"Mj3MrB6jXUMG"},"source":["### `negative_node_incrementation = True`\n","For this case we want the number of nodes to _decrease_ by a constant number for successive layers. <br>So `first_layer_nodes` must be _larger_ than `last_layer_nodes` "]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148,"status":"ok","timestamp":1639006068171,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":480},"id":"4m4jRNllXPPG","outputId":"e30bda1b-658e-40c9-8a74-dc228e6055b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of nodes in successive layers: [500, 400, 300, 200, 100]\n"]}],"source":["n_layers = 5\n","first_layer_nodes = 500\n","last_layer_nodes = 100\n","negative_node_incrementation = True\n","n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n","print(f'Number of nodes in successive layers: {n_nodes}')"]},{"cell_type":"markdown","metadata":{"id":"ttkaf3g9XhGr"},"source":["### `negative_node_incrementation = False`\n","For this case we want the number of nodes to _increase_ by a constant number for successive layers. <br>So `first_layer_nodes` must be _smaller_ than `last_layer_nodes` "]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":158,"status":"ok","timestamp":1639006083058,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":480},"id":"0fkrMS8bXQUo","outputId":"e7f849a8-831c-45b7-98f1-d369eb32a86b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of nodes in successive layers: [100, 200, 300, 400, 500]\n"]}],"source":["n_layers = 5\n","first_layer_nodes = 100\n","last_layer_nodes = 500\n","negative_node_incrementation = False\n","n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n","print(f'Number of nodes in successive layers: {n_nodes}')"]},{"cell_type":"markdown","metadata":{"id":"FHuB-bm5Wkpq"},"source":["### OK, the Unit Test is passed!"]},{"cell_type":"markdown","metadata":{"id":"qO3AjVWOZ6SA"},"source":["### Let's build a few models<br> \n","in order to understand how `create_model()` works in practice. "]},{"cell_type":"markdown","metadata":{"id":"95E85Ug07mNh"},"source":["### Build a model, setting `negative_node_incrementation = True` \n","\n","Use `create_model` to build a model. \n","\n","- Set `n_layers = 10` \n","- Set `first_layer_nodes = 500`\n","- Set `last_layer_nodes = 100`\n","- Set `act_funct = \"relu\"`\n"]},{"cell_type":"code","execution_count":10,"metadata":{"deletable":false,"id":"x_1REOCY7mNi","nbgrader":{"cell_type":"code","checksum":"5dcf5c585f07629a03086cf57ba53615","grade":false,"grade_id":"cell-86d63e89a21223de","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# use create_model to create a model \n","\n","model = create_model(n_layers=10, first_layer_nodes=500, last_layer_nodes=100,\n","                    act_funct='relu', negative_node_incrementation=True)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"sYMwZQ7k7mNi"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 500)               392500    \n","                                                                 \n"," dense_1 (Dense)             (None, 456)               228456    \n","                                                                 \n"," dense_2 (Dense)             (None, 412)               188284    \n","                                                                 \n"," dense_3 (Dense)             (None, 367)               151571    \n","                                                                 \n"," dense_4 (Dense)             (None, 323)               118864    \n","                                                                 \n"," dense_5 (Dense)             (None, 278)               90072     \n","                                                                 \n"," dense_6 (Dense)             (None, 234)               65286     \n","                                                                 \n"," dense_7 (Dense)             (None, 189)               44415     \n","                                                                 \n"," dense_8 (Dense)             (None, 145)               27550     \n","                                                                 \n"," dense_9 (Dense)             (None, 10)                1460      \n","                                                                 \n","=================================================================\n","Total params: 1,308,458\n","Trainable params: 1,308,458\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# run model.summary() and make sure that you understand the model architecture that you just built \n","# Notice in the model summary how the number of nodes have been linearly incremented in decreasing values. \n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"ZUc0jfnRm-uh"},"source":["### Build a model, setting `negative_node_incrementation = False` \n","\n","Use `create_model` to build a model. \n","\n","- Set `n_layers = 10` \n","- Set `first_layer_nodes = 100`\n","- Set `last_layer_nodes = 500`\n","- Set `act_funct = \"relu\"`"]},{"cell_type":"code","execution_count":12,"metadata":{"deletable":false,"id":"3_-kqHQtm-ui","nbgrader":{"cell_type":"code","checksum":"5dcf5c585f07629a03086cf57ba53615","grade":false,"grade_id":"cell-86d63e89a21223de","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# use create_model to create a model \n","\n","model = create_model(n_layers=10, first_layer_nodes=100, last_layer_nodes=500,\n","                    act_funct='relu', negative_node_incrementation=False)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"piboKWsNm-uj"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_10 (Dense)            (None, 100)               78500     \n","                                                                 \n"," dense_11 (Dense)            (None, 145)               14645     \n","                                                                 \n"," dense_12 (Dense)            (None, 189)               27594     \n","                                                                 \n"," dense_13 (Dense)            (None, 234)               44460     \n","                                                                 \n"," dense_14 (Dense)            (None, 278)               65330     \n","                                                                 \n"," dense_15 (Dense)            (None, 323)               90117     \n","                                                                 \n"," dense_16 (Dense)            (None, 367)               118908    \n","                                                                 \n"," dense_17 (Dense)            (None, 412)               151616    \n","                                                                 \n"," dense_18 (Dense)            (None, 456)               188328    \n","                                                                 \n"," dense_19 (Dense)            (None, 10)                4570      \n","                                                                 \n","=================================================================\n","Total params: 784,068\n","Trainable params: 784,068\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# run model.summary() and make sure that you understand the model architecture that you just built \n","# Notice in the model summary how the number of nodes have been linearly incremented in decreasing values. \n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"OBH7AR9p0OXi"},"source":["## 1.2 Create a grid search using `sklearn`"]},{"cell_type":"markdown","metadata":{"id":"veloj7Nnlttf"},"source":["### Hyperparameter search"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"3e2lhZqP7mNn"},"outputs":[],"source":["# define the grid search parameters\n","param_grid = {'n_layers': [2, 3],\n","              'epochs': [3], \n","              \"first_layer_nodes\": [500, 300],\n","              \"last_layer_nodes\": [100, 50]\n","             }"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"2Ks_MLPB7mNn"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-15-22e3fde777af>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n","  model = KerasClassifier(create_model)\n"]}],"source":["model = KerasClassifier(create_model)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":498795,"status":"ok","timestamp":1631204158958,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"m8GKbLJ_7mNn","outputId":"cf7d9084-4042-4518-a0ac-cdbd1edf1c4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 8 candidates, totalling 24 fits\n","Epoch 1/3\n","2344/2344 [==============================] - 13s 5ms/step - loss: 0.6134 - accuracy: 0.8189\n","Epoch 2/3\n","2344/2344 [==============================] - 11s 5ms/step - loss: 0.4223 - accuracy: 0.8741\n","Epoch 3/3\n","2344/2344 [==============================] - 12s 5ms/step - loss: 0.3443 - accuracy: 0.8970\n","Best: 0.8678933183352152 using {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 2}\n","Means: 0.8678933183352152, Stdev: 0.0010015062397189106 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 2}\n","Means: 0.8641066749890646, Stdev: 0.002907711379878512 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 3}\n","Means: 0.864680012067159, Stdev: 0.001906915861651792 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 2}\n","Means: 0.8637200196584066, Stdev: 0.004971281594282589 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 3}\n","Means: 0.8614400029182434, Stdev: 0.0008566435120431781 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 2}\n","Means: 0.8621866703033447, Stdev: 0.002465824842684746 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 3}\n","Means: 0.8578799962997437, Stdev: 0.001806933866054075 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n","Means: 0.8605733315149943, Stdev: 0.002217323846247674 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n","Wall time: 7min 3s\n"]}],"source":["%%time\n","# Create Grid Search\n","grid = GridSearchCV(estimator=model, \n","                    param_grid=param_grid, \n","                    n_jobs=-2, \n","                    verbose=1, \n","                    cv=3)\n","\n","grid_result = grid.fit(X_train, y_train)\n","\n","# Report Results\n","print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n","\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","\n","for mean, stdev, param in zip(means, stds, params):\n","    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"OfH6okqe7mNo"},"outputs":[],"source":["best_model = grid_result.best_estimator_"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Inlda_0w7mNo"},"outputs":[{"data":{"text/plain":["{'epochs': 3,\n"," 'first_layer_nodes': 500,\n"," 'last_layer_nodes': 100,\n"," 'n_layers': 2,\n"," 'build_fn': <function __main__.create_model(n_layers, first_layer_nodes, last_layer_nodes, act_funct='relu', negative_node_incrementation=True)>}"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["best_model.get_params()"]},{"cell_type":"markdown","metadata":{"id":"vrs3Yib17mNl"},"source":["Ok, now that we've played around a bit with  `create_model`, let's build a  simpler model that we'll use to run gridsearches. "]},{"cell_type":"markdown","metadata":{"id":"jvegpS1-5yYX"},"source":["### Build model\n","\n","Use `create_model` to build a model. \n","\n","- Set `n_layers = 2` \n","- Set `first_layer_nodes = 500`\n","- Set `last_layer_nodes = 100`\n","- Set `act_funct = \"relu\"`\n","- Make sure that `negative_node_incrementation = True`"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"p-NcKYRr5yYX","nbgrader":{"grade":false,"grade_id":"cell-4ca6c5e51302fd10","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# use create_model to create a model \n","\n","###BEGIN SOLUTION\n","# use create_model to create a model \n","model = create_model(n_layers=2, first_layer_nodes=500, last_layer_nodes=100,\n","                    act_funct='relu', negative_node_incrementation=True)\n","###END SOLUTION"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1633554004683,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"ICLd6cYN5yYY","outputId":"0e08e125-2923-4755-a562-df429d0fcab6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_22 (Dense)            (None, 500)               392500    \n","                                                                 \n"," dense_23 (Dense)            (None, 10)                5010      \n","                                                                 \n","=================================================================\n","Total params: 397,510\n","Trainable params: 397,510\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# run model.summary() and make sure that you understand the model architecture that you just built \n","model.summary()"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"KwY6GFo85yYY"},"outputs":[],"source":["# define the grid search parameters\n","param_grid = {'n_layers': [2, 3],\n","              'epochs': [3], \n","              \"first_layer_nodes\": [500, 300],\n","              \"last_layer_nodes\": [100, 50]\n","             }"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"8a0iHBqJ5yYY"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-22-22e3fde777af>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n","  model = KerasClassifier(create_model)\n"]}],"source":["model = KerasClassifier(create_model)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":304738,"status":"ok","timestamp":1633554309410,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"kxpuM3g15yYZ","outputId":"2ad0da1d-39be-4980-9b6c-02254002afa8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 8 candidates, totalling 24 fits\n","Epoch 1/3\n","2344/2344 [==============================] - 16s 6ms/step - loss: 0.5900 - accuracy: 0.8210\n","Epoch 2/3\n","2344/2344 [==============================] - 15s 6ms/step - loss: 0.4119 - accuracy: 0.8753\n","Epoch 3/3\n","2344/2344 [==============================] - 14s 6ms/step - loss: 0.3340 - accuracy: 0.8984\n","Best: 0.8670933445294698 using {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 3}\n","Means: 0.8629199862480164, Stdev: 0.003625671500082282 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 2}\n","Means: 0.8670933445294698, Stdev: 0.001200145454715468 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 100, 'n_layers': 3}\n","Means: 0.8666533430417379, Stdev: 0.0022649379700456205 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 2}\n","Means: 0.865506668885549, Stdev: 0.0005863687855380066 with: {'epochs': 3, 'first_layer_nodes': 500, 'last_layer_nodes': 50, 'n_layers': 3}\n","Means: 0.8616666793823242, Stdev: 0.005312065020135682 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 2}\n","Means: 0.865013321240743, Stdev: 0.00202499963202195 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 100, 'n_layers': 3}\n","Means: 0.8630800048510233, Stdev: 0.0013790961750143268 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 2}\n","Means: 0.8617199858029684, Stdev: 0.0013937002099415879 with: {'epochs': 3, 'first_layer_nodes': 300, 'last_layer_nodes': 50, 'n_layers': 3}\n","Wall time: 7min 4s\n"]}],"source":["%%time\n","# Create Grid Search\n","grid = GridSearchCV(estimator=model, \n","                    param_grid=param_grid, \n","                    n_jobs=-2, \n","                    verbose=1, \n","                    cv=3)\n","\n","grid_result = grid.fit(X_train, y_train)\n","\n","# Report Results\n","print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n","\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","\n","for mean, stdev, param in zip(means, stds, params):\n","    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"TIlpwjag5yYZ"},"outputs":[],"source":["best_model = grid_result.best_estimator_"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1633554309413,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"MFvMxmr85yYZ","outputId":"a4320b01-498e-41af-834d-4caeb8acf28a"},"outputs":[{"data":{"text/plain":["{'epochs': 3,\n"," 'first_layer_nodes': 500,\n"," 'last_layer_nodes': 100,\n"," 'n_layers': 3,\n"," 'build_fn': <function __main__.create_model(n_layers, first_layer_nodes, last_layer_nodes, act_funct='relu', negative_node_incrementation=True)>}"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["best_model.get_params()"]},{"cell_type":"markdown","metadata":{"id":"6azV65Nb7mNo"},"source":["-----\n","\n","# Experiment 2: Run the Gridsearch Algorithms \n","\n","In this section, we are going to use the same model and dataset in order to benchmark 3 different gridsearch approaches: \n","\n","- Gridsearch\n","- Random Search\n","- Bayesian Optimization. \n","\n","\n","Our goal in this experiment is two-fold. We want to see which appraoch \n","\n","- Scores the highest accuracy\n","- Has the shortest run time \n","\n","We want to see how these 3 gridsearch approaches handle these trade-offs and to give you a sense of those trades offs.\n","\n","### Trade-offs\n","\n","`Gridsearch` will train a model on every single unique hyperparameter combination, this guarantees that you'll get the highest possible accuracy from your parameter set but your gridsearch might have a very long run-time. \n","\n","`Random Search` will randomly sample from your parameter set which, depending on how many samples, the run-time might be significantly cut down but you might or might not sample the parameters that correspond to the heightest possible accuracies. \n","\n","`Bayesian Optimization` has a bit of intelligence built into it's search algorithm but you do need to manually select some parameters which may greatly influence the model learning outcomes. "]},{"cell_type":"markdown","metadata":{"id":"X41u_hls7mNp"},"source":["-------\n","### Build our model"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"wZ_uyKlj7mNp"},"outputs":[],"source":["# because gridsearching can take a lot of time and we are bench marking 3 different approaches\n","# let's build a simple model to minimize run time \n","\n","def build_model(hp):\n","    \n","    \"\"\"\n","    Returns a complied keras model ready for keras-tuner gridsearch algorithms \n","    \"\"\"\n","    \n","    model = Sequential()\n","    \n","    # hidden layer\n","    model.add(Dense(units=hp.get('units'),activation=hp.get(\"activation\")))\n","    \n","    # output layer\n","    model.add(Dense(10, activation='softmax'))\n","    \n","    model.compile(\n","        optimizer=Adam(hp.get('learning_rate')),\n","        loss='sparse_categorical_crossentropy',\n","        metrics=['accuracy'])\n","    \n","    return model\n","  "]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":198,"status":"ok","timestamp":1631141004011,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"PYE7rTku7mNp","outputId":"10c8a8f5-fd6d-46fb-e09e-032b0f13ef3a"},"outputs":[{"data":{"text/plain":["'relu'"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["# build out our hyperparameter dictionary \n","hp = HyperParameters()\n","hp.Int('units', min_value=32, max_value=512, step=32)\n","hp.Choice('learning_rate',values=[1e-1, 1e-2, 1e-3])\n","hp.Choice('activation',values=[\"relu\", \"sigmoid\"])"]},{"cell_type":"markdown","metadata":{"id":"zqjp2kHD7mNu"},"source":["---------\n","## 2.1 Gridsearch Optimization\n"]},{"cell_type":"markdown","metadata":{"id":"KsNW4rJp7mNu"},"source":["### Populate a `sklearn` compatible parameter dictionary"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"vJQFKoyL7mNu"},"outputs":[],"source":["# build out our hyperparameter dictionary \n","hyper_parameters = {\n","    # BUG Fix: cast array as list otherwise GridSearchCV will throw error\n","    \"units\": np.arange(32, 512, 32).tolist(),\n","    \"learning_rate\": [1e-1, 1e-2, 1e-3],\n","    \"activation\":[\"relu\", \"sigmoid\"]\n","}"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"RcxV58iC7mNu"},"outputs":[{"data":{"text/plain":["{'units': [32,\n","  64,\n","  96,\n","  128,\n","  160,\n","  192,\n","  224,\n","  256,\n","  288,\n","  320,\n","  352,\n","  384,\n","  416,\n","  448,\n","  480],\n"," 'learning_rate': [0.1, 0.01, 0.001],\n"," 'activation': ['relu', 'sigmoid']}"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["hyper_parameters"]},{"cell_type":"markdown","metadata":{"id":"rOoMg9Ao7mNv"},"source":["### Build a `sklearn` compatible model function"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"EZFVl-I-7mNv"},"outputs":[],"source":["def build_model(units, learning_rate, activation):\n","    \n","    \"\"\"\n","    Returns a complie keras model ready for keras-tuner gridsearch algorithms \n","    \"\"\"\n","    \n","    model = Sequential()\n","    \n","    # hidden layer\n","    model.add(Dense(units, activation=activation))\n","    \n","    # output layer\n","    model.add(Dense(10, activation='softmax'))\n","    \n","    model.compile(\n","        optimizer=Adam(learning_rate),\n","        loss='sparse_categorical_crossentropy',\n","        metrics=['accuracy'])\n","    \n","    return model"]},{"cell_type":"markdown","metadata":{"id":"uqYmn3QFsqZ_"},"source":["### Apply the \"wrapper\" to make the model compatible with `sklearn`"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"ABSzrTrH7mNw"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-31-a93dc876c14b>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n","  model = KerasClassifier(build_fn = build_model)\n"]}],"source":["model = KerasClassifier(build_fn = build_model)"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"tTawllrN7mNw","jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 90 candidates, totalling 270 fits\n","2344/2344 [==============================] - 14s 5ms/step - loss: 0.6164 - accuracy: 0.8178\n","Best: 0.8441333373387655 using {'activation': 'relu', 'learning_rate': 0.001, 'units': 480}\n","Means: 0.2871599992116292, Stdev: 0.03064962482845925 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 32}\n","Means: 0.29363999764124554, Stdev: 0.04350228884734625 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 64}\n","Means: 0.27585333089033764, Stdev: 0.05732066951201459 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 96}\n","Means: 0.2894800007343292, Stdev: 0.024401586285257473 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 128}\n","Means: 0.2632799943288167, Stdev: 0.018134101420115192 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 160}\n","Means: 0.3020133276780446, Stdev: 0.028425465566921704 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 192}\n","Means: 0.24423999587694803, Stdev: 0.005097863808187666 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 224}\n","Means: 0.3184400002161662, Stdev: 0.025716493752348753 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 256}\n","Means: 0.3587466776371002, Stdev: 0.048213409145719074 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 288}\n","Means: 0.27983999252319336, Stdev: 0.03787525648407367 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 320}\n","Means: 0.24027999738852182, Stdev: 0.005838999001763004 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 352}\n","Means: 0.3137066662311554, Stdev: 0.019459402029755924 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 384}\n","Means: 0.28737333913644153, Stdev: 0.04401678740797813 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 416}\n","Means: 0.24970666567484537, Stdev: 0.026413374559745476 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 448}\n","Means: 0.31282666325569153, Stdev: 0.031284364916019165 with: {'activation': 'relu', 'learning_rate': 0.1, 'units': 480}\n","Means: 0.7842533191045126, Stdev: 0.008287200793839562 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 32}\n","Means: 0.792959988117218, Stdev: 0.007647088361632983 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 64}\n","Means: 0.8030799825986227, Stdev: 0.006418559021268241 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 96}\n","Means: 0.8016266624132792, Stdev: 0.003222795550920621 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 128}\n","Means: 0.7985999981562296, Stdev: 0.010252485412774905 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 160}\n","Means: 0.8028666575749716, Stdev: 0.004815143067201126 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 192}\n","Means: 0.8009600043296814, Stdev: 0.008044341788179902 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 224}\n","Means: 0.8044533332188925, Stdev: 0.005817165533418242 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 256}\n","Means: 0.8037466804186503, Stdev: 0.0003896479961626192 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 288}\n","Means: 0.7969866792360941, Stdev: 0.004882110188695943 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 320}\n","Means: 0.7971466779708862, Stdev: 0.004131731899803223 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 352}\n","Means: 0.8054666717847189, Stdev: 0.010047171842120332 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 384}\n","Means: 0.7943866650263468, Stdev: 0.0018406728507982342 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 416}\n","Means: 0.8008666435877482, Stdev: 0.011074073859963474 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 448}\n","Means: 0.8061333298683167, Stdev: 0.00336530489427649 with: {'activation': 'relu', 'learning_rate': 0.01, 'units': 480}\n","Means: 0.786733349164327, Stdev: 0.0026910745058808397 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 32}\n","Means: 0.8094533284505209, Stdev: 0.00269050987301137 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 64}\n","Means: 0.8234666585922241, Stdev: 0.0022890761458120193 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 96}\n","Means: 0.8205599983533224, Stdev: 0.005345748564186749 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 128}\n","Means: 0.8314400116602579, Stdev: 0.0033547562800152965 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 160}\n","Means: 0.8340933322906494, Stdev: 0.001068496135044809 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 192}\n","Means: 0.8348933259646097, Stdev: 0.0027356958709092018 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 224}\n","Means: 0.8388933340708414, Stdev: 0.0019350352497723802 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 256}\n","Means: 0.8375466465950012, Stdev: 0.005027957563348315 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 288}\n","Means: 0.836079994837443, Stdev: 0.0022416631520219524 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 320}\n","Means: 0.837826669216156, Stdev: 0.0032503217913304344 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 352}\n","Means: 0.8373599847157797, Stdev: 0.0009933197754691874 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 384}\n","Means: 0.838919997215271, Stdev: 0.0017383342300279566 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 416}\n","Means: 0.838866670926412, Stdev: 0.004232219000661772 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 448}\n","Means: 0.8441333373387655, Stdev: 0.0005621991706250305 with: {'activation': 'relu', 'learning_rate': 0.001, 'units': 480}\n","Means: 0.6334666609764099, Stdev: 0.04235887195604799 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 32}\n","Means: 0.6590266625086466, Stdev: 0.007953348816524281 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 64}\n","Means: 0.6719200213750204, Stdev: 0.009183118957275893 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 96}\n","Means: 0.665559987227122, Stdev: 0.01809576949906064 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 128}\n","Means: 0.6878400047620138, Stdev: 0.019046415459834418 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 160}\n","Means: 0.6518133481343588, Stdev: 0.025706242291462983 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 192}\n","Means: 0.6621866424878439, Stdev: 0.0157219236639635 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 224}\n","Means: 0.5923733512560526, Stdev: 0.05100773733306099 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 256}\n","Means: 0.6189333399136862, Stdev: 0.04632709316834666 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 288}\n","Means: 0.6428399880727133, Stdev: 0.015087200562467774 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 320}\n","Means: 0.6251999934514364, Stdev: 0.023277193746878796 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 352}\n","Means: 0.6473866701126099, Stdev: 0.03275984308878303 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 384}\n","Means: 0.577239990234375, Stdev: 0.08389544881136402 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 416}\n","Means: 0.663973331451416, Stdev: 0.005474830592279683 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 448}\n","Means: 0.6468666593233744, Stdev: 0.010001831360388923 with: {'activation': 'sigmoid', 'learning_rate': 0.1, 'units': 480}\n","Means: 0.7845066785812378, Stdev: 0.002894480874363351 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 32}\n","Means: 0.8076800107955933, Stdev: 0.0028578867789367263 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 64}\n","Means: 0.8124266465504965, Stdev: 0.004198067559447502 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 96}\n","Means: 0.8119866649309794, Stdev: 0.0014636236137625957 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 128}\n","Means: 0.8190000057220459, Stdev: 0.003431162379997221 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 160}\n","Means: 0.8142133355140686, Stdev: 0.00478065881059985 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 192}\n","Means: 0.8068400025367737, Stdev: 0.008092727595846023 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 224}\n","Means: 0.817466676235199, Stdev: 0.0033722595374547763 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 256}\n","Means: 0.813093344370524, Stdev: 0.0024710338545090617 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 288}\n","Means: 0.8167466521263123, Stdev: 0.003351469434242467 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 320}\n","Means: 0.8185199896494547, Stdev: 0.009645274692105646 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 352}\n","Means: 0.8160666624704996, Stdev: 0.006569957681475289 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 384}\n","Means: 0.8211333354314169, Stdev: 0.0023085422930386964 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 416}\n","Means: 0.8200666904449463, Stdev: 0.004681004488832053 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 448}\n","Means: 0.8167733550071716, Stdev: 0.008013886069558412 with: {'activation': 'sigmoid', 'learning_rate': 0.01, 'units': 480}\n","Means: 0.7572266658147176, Stdev: 0.0007948634495168656 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 32}\n","Means: 0.7778000036875407, Stdev: 0.002599898527273428 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 64}\n","Means: 0.7840533256530762, Stdev: 0.004588954952793992 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 96}\n","Means: 0.7886933286984762, Stdev: 0.003886567179371603 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 128}\n","Means: 0.794053335984548, Stdev: 0.001739690887201197 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 160}\n","Means: 0.794866661230723, Stdev: 0.0030875692555242286 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 192}\n","Means: 0.7973466714223226, Stdev: 0.004765334754077886 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 224}\n","Means: 0.7989200154940287, Stdev: 0.0011973208958184938 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 256}\n","Means: 0.8004399935404459, Stdev: 0.004537587083258138 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 288}\n","Means: 0.8018933335940043, Stdev: 0.0009999077924873867 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 320}\n","Means: 0.7987599968910217, Stdev: 0.006404247027054157 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 352}\n","Means: 0.8040666778882345, Stdev: 0.0029091749799276746 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 384}\n","Means: 0.802346666653951, Stdev: 0.0026360266971837886 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 416}\n","Means: 0.8039600054423014, Stdev: 0.0020606753530535847 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 448}\n","Means: 0.7995199958483378, Stdev: 0.002791042180888117 with: {'activation': 'sigmoid', 'learning_rate': 0.001, 'units': 480}\n"]}],"source":["# save start time \n","start = time()\n","\n","# Create Grid Search\n","grid = GridSearchCV(estimator=model, \n","                    param_grid=hyper_parameters, \n","                    n_jobs=-2, \n","                    verbose=1, \n","                    cv=3)\n","\n","grid_result = grid.fit(X_train, y_train)\n","\n","# save end time \n","end = time()\n","\n","# Report Results\n","print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n","\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","\n","for mean, stdev, param in zip(means, stds, params):\n","    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"THKMZLNv7mNw"},"outputs":[{"data":{"text/plain":["18.615281403064728"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# total run time \n","total_run_time_in_miniutes = (end - start)/60\n","total_run_time_in_miniutes"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"4XgJsrZb7mNx"},"outputs":[{"data":{"text/plain":["{'activation': 'relu', 'learning_rate': 0.001, 'units': 480}"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["grid_result.best_params_"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"aYufbSI87mNx"},"outputs":[{"name":"stdout","output_type":"stream","text":["782/782 [==============================] - 5s 3ms/step - loss: 0.4894 - accuracy: 0.8524\n"]}],"source":["# because all other optimization approaches are reporting test set score\n","# let's calculate the test set score in this case \n","best_model = grid_result.best_estimator_\n","test_acc = best_model.score(X_test, y_test)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"BlR-pVwP7mNx"},"outputs":[{"data":{"text/plain":["0.8524399995803833"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["test_acc"]},{"cell_type":"markdown","metadata":{"id":"Gj4jJ0Qm7mNx"},"source":[" ### Results\n"," \n","Identify and write the the best performing hyperparameter combination and model score. \n"," \n"," "]},{"cell_type":"markdown","metadata":{"deletable":false,"id":"10px3N2q7mNx","nbgrader":{"cell_type":"markdown","checksum":"9577db883482c6cded3836e5cfbf5a74","grade":true,"grade_id":"cell-eb06d682d2790f6e","locked":false,"points":0,"schema_version":3,"solution":true,"task":false}},"source":["- Best hyperparameters: ReLU activation, learning rate 0.001, 480 nodes in 1 hidden layer\n","- Best model score: 0.85244"]},{"cell_type":"markdown","metadata":{"id":"zu-lBWph7mNq"},"source":["------\n","## 2.2 Random Search with `keras-tuner`\n","\n","Be sure to check out the [**docs for Keras-Tuner**](https://keras-team.github.io/keras-tuner/documentation/tuners/). Here you can read about the input parameters for the `RandomSearch` tuner."]},{"cell_type":"code","execution_count":39,"metadata":{"deletable":false,"id":"8DApqLli7mNq","nbgrader":{"cell_type":"code","checksum":"aaff9aae33845f374e15f2381719d83a","grade":false,"grade_id":"cell-8c1dfb9b6d12bea2","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[{"data":{"text/plain":["90"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["# how many unique hyperparameter combinations do we have? \n","# HINT: take the product of the number of possible values for each hyperparameter \n","# save your answer to n_unique_hparam_combos\n","\n","# YOUR CODE HERE\n","n_unique_hparam_combos = len(hyper_parameters['units']) * len(hyper_parameters['learning_rate']) * len(hyper_parameters['activation'])\n","n_unique_hparam_combos"]},{"cell_type":"code","execution_count":42,"metadata":{"deletable":false,"id":"m1UKRA597mNq","nbgrader":{"cell_type":"code","checksum":"a9d628451e83431e1b52da10eccf2c00","grade":false,"grade_id":"cell-1fa83950bb2d5f92","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[{"data":{"text/plain":["22"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["# how many of these do we want to randomly sample?\n","# let's pick 25% of n_unique_hparam_combos param combos to sample\n","# save this number to n_param_combos_to_sample\n","\n","# YOUR CODE HERE\n","fraction_to_sample = 0.25\n","n_param_combos_to_sample = round((fraction_to_sample * n_unique_hparam_combos))\n","n_param_combos_to_sample"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# build out our hyperparameter dictionary \n","hp = HyperParameters()\n","hp.Int('units', min_value=32, max_value=512, step=32)\n","hp.Choice('learning_rate',values=[1e-1, 1e-2, 1e-3])\n","hp.Choice('activation',values=[\"relu\", \"sigmoid\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZ_uyKlj7mNp"},"outputs":[],"source":["# because gridsearching can take a lot of time and we are bench marking 3 different approaches\n","# let's build a simple model to minimize run time \n","\n","def build_model(hp):\n","    \n","    \"\"\"\n","    Returns a complied keras model ready for keras-tuner gridsearch algorithms \n","    \"\"\"\n","    \n","    model = Sequential()\n","    \n","    # hidden layer\n","    model.add(Dense(units=hp.get('units'),activation=hp.get(\"activation\")))\n","    \n","    # output layer\n","    model.add(Dense(10, activation='softmax'))\n","    \n","    model.compile(\n","        optimizer=Adam(hp.get('learning_rate')),\n","        loss='sparse_categorical_crossentropy',\n","        metrics=['accuracy'])\n","    \n","    return model\n","  "]},{"cell_type":"markdown","metadata":{"id":"1TzaNnzoQU4U"},"source":["### Instantiate a `RandomSearch()` object for your grid search"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"Y9PCHLBWQPcb"},"outputs":[],"source":["random_tuner = RandomSearch(\n","            build_model, # instantiate hypermodel version above before running\n","            objective='val_accuracy',\n","            max_trials=n_param_combos_to_sample, # number of times to sample the parameter set and build a model \n","            seed=1234,\n","            hyperparameters=hp, # pass in our hyperparameter dictionary\n","            directory='./keras-tuner-trial',\n","            project_name='random_search')"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":609103,"status":"ok","timestamp":1631141924575,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"OGFdv1qE7mNr","outputId":"f4fb1482-c4bc-40cd-c426-d8248e67341f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Trial 22 Complete [00h 00m 26s]\n","val_accuracy: 0.2553600072860718\n","\n","Best val_accuracy So Far: 0.8716800212860107\n","Total elapsed time: 00h 10m 14s\n","INFO:tensorflow:Oracle triggered exit\n"]}],"source":[" # take note of Total elapsed time in print out -- took ~10 minutes without GPU\n","random_tuner.search(X_train, y_train,\n","                    epochs=3,\n","                    validation_data=(X_test, y_test))"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":150,"status":"ok","timestamp":1631144598023,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"zNBUhIe97mNr","outputId":"a12fb52d-eec7-4b72-a2d0-cfb8482ade48"},"outputs":[{"name":"stdout","output_type":"stream","text":["Results summary\n","Results in ./keras-tuner-trial\\random_search\n","Showing 10 best trials\n","<keras_tuner.engine.objective.Objective object at 0x0000000015E591C0>\n","Trial summary\n","Hyperparameters:\n","units: 384\n","learning_rate: 0.001\n","activation: relu\n","Score: 0.8716800212860107\n","Trial summary\n","Hyperparameters:\n","units: 352\n","learning_rate: 0.001\n","activation: relu\n","Score: 0.8676400184631348\n","Trial summary\n","Hyperparameters:\n","units: 480\n","learning_rate: 0.001\n","activation: sigmoid\n","Score: 0.8647199869155884\n","Trial summary\n","Hyperparameters:\n","units: 416\n","learning_rate: 0.001\n","activation: sigmoid\n","Score: 0.8640000224113464\n","Trial summary\n","Hyperparameters:\n","units: 448\n","learning_rate: 0.001\n","activation: sigmoid\n","Score: 0.8565999865531921\n","Trial summary\n","Hyperparameters:\n","units: 224\n","learning_rate: 0.001\n","activation: sigmoid\n","Score: 0.8549200296401978\n","Trial summary\n","Hyperparameters:\n","units: 320\n","learning_rate: 0.01\n","activation: sigmoid\n","Score: 0.8436400294303894\n","Trial summary\n","Hyperparameters:\n","units: 160\n","learning_rate: 0.01\n","activation: sigmoid\n","Score: 0.8386399745941162\n","Trial summary\n","Hyperparameters:\n","units: 192\n","learning_rate: 0.01\n","activation: sigmoid\n","Score: 0.8352000117301941\n","Trial summary\n","Hyperparameters:\n","units: 320\n","learning_rate: 0.01\n","activation: relu\n","Score: 0.824679970741272\n"]}],"source":["# identify the best score and hyperparamter (should be at the top since scores are ranked)\n","random_tuner.results_summary()"]},{"cell_type":"markdown","metadata":{"id":"FRpQVXBE7mNr","jupyter":{"source_hidden":true}},"source":[" ### Results\n"," \n","Identify and write the the best performing hyperparameter combination and model score. \n","Note that because this is Random Search, multiple runs might have slighly different outcomes. \n"," \n"," "]},{"cell_type":"markdown","metadata":{"deletable":false,"id":"aQjMc84c7mNs","nbgrader":{"cell_type":"markdown","checksum":"f084b5d373f8589a1de8d6d4473b974a","grade":true,"grade_id":"cell-5527738b6382c164","locked":false,"points":0,"schema_version":3,"solution":true,"task":false}},"source":["- Best hyperparameters: ReLU activation, learning rate 0.001, 384 nodes in 1 hidden layer\n","- Best model score: 0.87168"]},{"cell_type":"markdown","metadata":{"id":"vXjW7eYA7mNs"},"source":["------\n","## 2.3 Bayesian Optimization with `keras-tuner`\n","\n","![](https://upload.wikimedia.org/wikipedia/commons/0/02/GpParBayesAnimationSmall.gif)\n","\n","Be sure to check out the [**docs for Keras-Tuner**](https://keras-team.github.io/keras-tuner/documentation/tuners/). Here you can read about the input parameters for the `BayesianOptimization` tuner.\n","\n","Pay special attention to these `BayesianOptimization` parameters: `num_initial_points` and `beta`. \n","\n","`num_initial_points`: \n","\n","Number of randomly selected hyperparameter combinations to try before applying bayesian probability to determine liklihood of which param combo to try next based on expected improvement\n","\n","\n","`beta`: \n","\n","Larger values means more willing to explore new hyperparameter combinations (analogous to searching for the global minimum in Gradient Descent), smaller values means that it is less willing to try new hyperparameter combinations (analogous to getting stuck in a local minimum in Gradient Descent). \n","\n","As a start, error on the side of larger values. What defines a small or large value you ask? That question would pull us into the mathematical intricacies of Bayesian Optimization and Gaussian Processes. For simplicity, notice that the default value is 2.6 and work from there. "]},{"cell_type":"code","execution_count":57,"metadata":{"id":"_NXjQBn47mNs"},"outputs":[],"source":["# we know that 24 samples is about 25% of 96 possible hyper-parameter combos\n","# let's set up a run with the same parameters we used for RandomSearch() so the comparison will be aplles-to-apples\n","# feel free to play with any of these numbers later\n","max_trials=24\n","num_initial_points=5\n","beta=5.0"]},{"cell_type":"markdown","metadata":{"id":"HhZNIJZ4RS5Y"},"source":["#### Instantiate a `BayesianOptimization()` object for your grid search"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":354,"status":"ok","timestamp":1631144696927,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"33joO_J97mNs","outputId":"9241d1ca-eed3-433f-9188-e854e808afd1"},"outputs":[],"source":["bayesian_tuner = BayesianOptimization(\n","                    build_model,\n","                    objective='val_accuracy',\n","                    max_trials=max_trials,\n","                    hyperparameters=hp, # pass in our hyperparameter dictionary\n","                    num_initial_points=num_initial_points, \n","                    beta=beta, \n","                    seed=1234,\n","                    directory='./keras-tuner-trial',\n","                    project_name='bayesian_optimization_4')"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":185918,"status":"ok","timestamp":1631144887308,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"h9AM5Pdj7mNt","outputId":"6ca1e102-3836-4d46-c535-572f8a7f085c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Trial 24 Complete [00h 00m 18s]\n","val_accuracy: 0.8284000158309937\n","\n","Best val_accuracy So Far: 0.8729199767112732\n","Total elapsed time: 00h 09m 59s\n","INFO:tensorflow:Oracle triggered exit\n"]}],"source":["bayesian_tuner.search(X_train, y_train,\n","               epochs=3,\n","               validation_data=(X_test, y_test))"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1631144887310,"user":{"displayName":"Joseph catanzarite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmMRaw8NgoEDqzevEZ6b18iOYdEH9nWTZeaFBW=s64","userId":"16649206137414945374"},"user_tz":420},"id":"FJcHC8d87mNt","jupyter":{"outputs_hidden":true},"outputId":"a610cf67-6251-4976-9409-30a57ed02be9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Results summary\n","Results in ./keras-tuner-trial\\bayesian_optimization_4\n","Showing 10 best trials\n","<keras_tuner.engine.objective.Objective object at 0x0000000006367910>\n","Trial summary\n","Hyperparameters:\n","units: 352\n","learning_rate: 0.001\n","activation: relu\n","Score: 0.8729199767112732\n","Trial summary\n","Hyperparameters:\n","units: 512\n","learning_rate: 0.001\n","activation: relu\n","Score: 0.8686400055885315\n","Trial summary\n","Hyperparameters:\n","units: 480\n","learning_rate: 0.001\n","activation: sigmoid\n","Score: 0.8600000143051147\n","Trial summary\n","Hyperparameters:\n","units: 256\n","learning_rate: 0.001\n","activation: sigmoid\n","Score: 0.8528800010681152\n","Trial summary\n","Hyperparameters:\n","units: 32\n","learning_rate: 0.001\n","activation: relu\n","Score: 0.8300399780273438\n","Trial summary\n","Hyperparameters:\n","units: 32\n","learning_rate: 0.001\n","activation: relu\n","Score: 0.8284000158309937\n","Trial summary\n","Hyperparameters:\n","units: 32\n","learning_rate: 0.001\n","activation: relu\n","Score: 0.8281599879264832\n","Trial summary\n","Hyperparameters:\n","units: 32\n","learning_rate: 0.001\n","activation: relu\n","Score: 0.8274000287055969\n","Trial summary\n","Hyperparameters:\n","units: 32\n","learning_rate: 0.001\n","activation: relu\n","Score: 0.8259599804878235\n","Trial summary\n","Hyperparameters:\n","units: 32\n","learning_rate: 0.001\n","activation: relu\n","Score: 0.8258799910545349\n"]}],"source":["bayesian_tuner.results_summary()"]},{"cell_type":"markdown","metadata":{"id":"woo9D9AU7mNu"},"source":[" ### Results\n"," \n","Identify and write the the best performing hyperparameter combination and model score. \n","Note that because this is  Bayesian Optimization, multiple runs might have slighly different outcomes. \n"," \n"," "]},{"cell_type":"markdown","metadata":{"deletable":false,"id":"1EXa47mH7mNu","nbgrader":{"cell_type":"markdown","checksum":"1badcdca408cdd49bc2e409dca3bac5a","grade":true,"grade_id":"cell-ff95600bf745f40f","locked":false,"points":0,"schema_version":3,"solution":true,"task":false}},"source":["- Best hyperparameters: ReLU activation, learning rate 0.001, 352 nodes in 1 hidden layer\n","- Best model score: 0.87292\n","- Notes: Slightly better score than random search for approx. the same runtime"]},{"cell_type":"markdown","metadata":{"id":"OOZ5-tJDraFE"},"source":["We should point out that Gridsearch split the training set internally and created a test set whereas keras-tuner allows us to pass in a test set. This means that the keras-tuner algorithms were using one test set and our skearn GridSearchCV was using a different test set - so this isn't a perfectly exact 1-to-1 comparision but it'll have to do. In order to compensate for this, we did score the best model on the same test set that keras-tuner used. "]},{"cell_type":"markdown","metadata":{"id":"dPYChhrC7mNx"},"source":["_______\n","\n","# Conclusion\n","\n","The spirit of this experiment is to expose you to the idea of benchmarking and comparing the trade-offs of various gridsearch approaches. \n","\n","Even if we did find a way to pass in the original test set into GridSearchCV, we can see that both Random Search and Bayesian Optimization are arguably better alternatives to a brute force grid search when we consider the trade-offs of run time and locating the best performing model. "]},{"cell_type":"markdown","metadata":{"id":"Sth1AfwX7mNy"},"source":["----\n","\n","# Stretch Goals\n","\n","- Feel free to run whatever gridsearch experiments on whatever models you like!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H2APQG9H7mNy"},"outputs":[],"source":["# this is your open playground - be free to explore as you wish "]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"DS_423_Tune_Assignment.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.8.8 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"nteract":{"version":"0.22.4"},"vscode":{"interpreter":{"hash":"687c238b3ce093b6d05593c14198ba6d4a27c356ca33aff629c1e2e7517a29f8"}}},"nbformat":4,"nbformat_minor":0}
